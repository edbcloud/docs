---
title: BART Migration Journey
 
---

Introduction
==============

As EDB is introducing two new backup tools (Barman and pgBackRest), you
can use this document as a reference for migrating from BART to Barman
or pgBackRest.

This document includes:

-   How to configure Barman or pgBackRest based on an existing BART configuration

-   Recommendations on how to migrate from BART to Barman or pgBackRest

-   How to restore BART backups without using BART

Tool comparison
=================

When migrating from BART, EDB supports two other backup tools: Barman
and pgBackRest. This chapter will bring you a short introduction to the
different tools, and their different strengths and weaknesses as
provided by EDB. Hopefully find the right tool for your needs. If needed
you will find more information in the documentation regarding these
specific tools:

-   [Generic information regarding backup](https://www.enterprisedb.com/products/postgresql-database-auto-backup-recovery-restore-script-tools)

-   [Barman documentation](https://www.enterprisedb.com/docs/supported-open-source/barman/)

-   [pgBackRest documentation](https://www.enterprisedb.com/docs/supported-open-source/pgbackrest/)

Barman
----------

Barman would be the right choice for remote backups using the PostgreSQL
port, which is not relying on setting up passwordless ssh. Additionally,
EDB has selected Barman to be the new strategic backup tool. Barman will
be closely integrated with the rest of the tooling, with targets on the
roadmap like PEM integration, integration with Backup solutions, and
supporting an API for integration with other tools.

pgBackRest
--------------

pgBackRest is expected to have a performance benefit for backing up
large (multi-terabyte) databases. The internal algorithm for detecting
file changes in delta backups adds less overhead, and partial restore
allows to restore only one database from a large multi database cluster.
An additional advantage is that pgBackRest already supplies backup
compression, which is a planned feature for Barman (Q3 2021).

Comparison matrix
---------------------

The following selection matrix might help to differentiate between the
tools on a generic level:

  **Capability**                              **Barman**                                                                          **pgBackRest**
  ------------------------------------------- ----------------------------------------------------------------------------------- -----------------------------------------------------------------------------------
  SSH protocol support                        Yes                                                                                 Yes
  PostgreSQL protocol                         Yes                                                                                 -
  Incremental backups                         Yes                                                                                 Yes
  RPO=0                                       Yes                                                                                 -
  Rate limiting                               Yes                                                                                 -
  Custom WAL sizes                            Yes                                                                                 Yes ( v11+)
  WAL archive compression                     Yes                                                                                 Yes
  Backup compression                          Q4                                                                                  Yes
  Symmetric encryption                        -                                                                                   Yes
  Parallel backup and restore                 Yes                                                                                 Yes
  Partial restore (only selected databases)   -                                                                                   Yes
  Centralized repository management           Yes                                                                                 Yes
  Retention policy                            Yes                                                                                 Yes
  List backup                                 Yes                                                                                 Yes
  S3 support                                  Yes                                                                                 Yes
  Nagios integration                          Yes                                                                                 Yes
  PEM integration                             Q3                                                                                  -
  No custom scripts required                  Yes                                                                                 Yes
  License                                     [GPLv3](https://github.com/EnterpriseDB/barman/blob/master/LICENSE)                 [MIT](https://github.com/pgbackrest/pgbackrest/blob/master/LICENSE)

Tool selection
------------------

Which tool is the right tool for your environment very much depends on
your specific needs, but we hope that this chapter has enabled you to
select the right tool. Should you still have questions, or require
further assistance, please reach out to us through the following
channels:

Customer Email: techsupport\@enterprisedb.com

Trial Use Assistance: trial-help\@enterprisedb.com

Phone:

US +1-732-331-1320 / 1-800-235-5891

UK +44-2033719820

Brazil +55-2139581371

India +91-20-66449612

Planning the migration
========================

For planning your migration, EDB recommends to make sure the following
items should be included in your migration plan:

Testing and verification 
-----------------------------

Every organization will have different policies and capabilities which
define what should be done in which environment. Some organizations
restore a production database after migration to a temporary system in
the test environment, where others rather test the process in a test
environment, and expect their production environment to behave the same
as their test environment. Whatever best suits your organization, make
sure all of the following are updated and verified:

-   Deployment and management automation

-   Processes for restoring a database

-   Integrations such as integrations with the backup infrastructure

EDB advises to set up a temporary test system, specifically for
onboarding the new tool, so that all of these actions can take place
without impacting the existing environments. Make sure your test plan
includes standing up the test system, planning for all actions that
should take place on this test system, and cleaning up the system after
migration.

Some organizations also require verifying a successful restore for every
database that has been migrated to the new tool.

Sizing considerations
-------------------------

Depending on the actual migration, different sizing considerations
apply. Two distinct migration paths exist:

1.  New storage will be attached for the new backups.

 In this case, a good starting point would be to size the storage equally to the current sizing requirements. Note this might be a good opportunity to scale down oversized storage locations. Optionally, consider running both backup tools simultaneously. If the impact is acceptable, it can be an option for rollback and extra security for successful backups. EDB recommends this approach as it is the most straightforward and least error prone.

2.  The mount point for the existing backups is reused for the backups.

 An important note to make is that the repositories for the different tools have different layouts, and are not interchangeable. That means that the exact location needs to be distinct. But they can exist on the same mount point. The upside is that the extra required storage can be expected to be less than when attaching new storage. That being said, during migration extra storage is still required, and downscaling might not be an option. Furthermore, this option leaves no room to run both backup tools simultaneously. Extra sizing requirements would depend on your exact backup scheme, maintenance schema, and the size difference for differential backups. A good starting point would be to prepare for an extra set of backups (1 full and all differentials), and an extra full backup. Make sure that the monitoring thresholds are also properly adjusted as required.

 Note that it is crucial that you make sure that compression options are configured similarly between the old and new tool. Alternatively, extra storage space is required to compensate for the backup and/or WAL size.

During the planning phase the following needs to be taken care of:

-   Select the approach.

-   Size the expected extra storage and check for availability.

-   Plan to attach or increase the extra storage as part of the migration plan.

-   Next to the expected extra storage, also make sure that during the migration extra storage space is directly available should it be required due to unforeseen circumstances.

-   When using the first approach (extra mount point), plan to clean out the old storage after migration. Make sure that the old repositories are preserved long enough to meet your organization's rollback policies.

Intermediate situation
--------------------------

Depending on the size of your environment, the number of available
resources (DBA\'s) to run the migrations, and the amount of automation,
the migration can take a considerable amount of time. During the
migration your organization may be stressed with some parts of the
environment already running with the new tool, extra storage
requirements being identified, and DBA resources focused on the
migration and less available for other tasks.

It is therefore crucial to plan the migration per environment and derive
the duration of the migration from that plan. Communicate these
timelines to the rest of the organization so that they are aware that
the DBA team is extra occupied during this period of time. Furthermore,
make sure that the storage team is available to prepare for and attach
the extra storage as required.

Another item to think about while planning the migration is to make a
risk assessment and identify mitigations.

Other planning
------------------

Read through the sections on execution, maintenance, and cleanup, and
make sure all steps are part of your migration plan as well.

After compiling your migration plan, communicating with the
organization, and freeing the required resources, you are now ready for
execution.

Execution
===========

Execution of the migration can be very straight forward. The steps include:

1.  Adding extra storage capacity to the backup server

    -   As a new mount point when migrating to a new mount point (or Cloud Storage endpoints).

    -   As extra storage on the existing mount point when reusing the same mount point.

2.  Installing the new tool on the backup server

3.  Configuring the configuration file for the new tool. See  [How features are configured](#how-features-are-configured) for more information on changing a configuration file for one tool to another tool.

4.  Reconfiguring the scheduling. See  [Scheduling](#scheduling) for more information on changing the scheduling from one tool to another tool.

5.  Checking the configuration

    -   `barman check <example>`

    -   `pgbackrest --stanza=<example> --log-level-console=info check`

 Fix any issues.

6.  Running an initial backup manually, before relying on the scheduling
    (recommended). The check commands will recover the most common
    issues, but there could always still be unforeseen issues, like
    storage space issues, IO or network latency issues, etc. It would
    be unfortunate if the scheduled backups fail since that would
    increase risk for unsuccessful restores. As your team runs more
    migrations, they will gain more confidence to skip this step as
    required.

7.  Some organizations might prefer to actually restore and recover the
    backup (on a separate system), and check for the expected data.
    This is only an optional extra step, which greatly depends on your
    organization's policies.

Maintenance and cleanup
=========================

A warmup period is required after the migration. This is because:

-   With an empty repository there will be more situations where a full
    backup is created, where in a normal situation a differential
    backup would be taken.

-   The maintenance process of cleaning old backups kicks in only after
    exceeding the retention period.

During this warmup time, extra care needs to be taken on the backups to
make sure that any backup issue is identified and fixed. Options
include:

-   Increasing monitoring notification levels and decreasing alert thresholds for free space.

-   Planning manual checks of the backups during the migration.

EDB recommends keeping the original backup solution around during this
'warm up period'. You may want to keep the systems around for a longer
period of time as an extra safety measure or extra rollback option. When
the system is warmed up, and the extra rollback time has exceeded, the
old systems can be deprovisioned by:

-   Removing the original tool from the system.

-   Deprovisioning the old mount point and storage after the new mount point is attached for the new storage repository.

-   Deprovisioning the old servers If the new tool runs on new servers.

Configuration of the different tools
======================================

This chapter draws a comparison between the three tools and shows how
they differ in configuration (config file), and in scheduling. During a
migration it is important to be aware of all of these differences, and
apply changes as necessary.

How features are configured
-------------------------------

The table below shows features of the different tools, and how to enable
them in configuration and/or with command line options. The way to
configure is grouped per feature, so that the way to implement can be
easily compared across the tools.

**List of features**

-   [Postgres connection details](#postgres_conn_details)

-   [Use of direct file copy mode (ssh or rsync) instead of pg_basebackup](#direct_file_copy_mode)

-   [Incremental backups](#incremental_backup)

-   [WAL archive compression](#wal_archive_compression)

-   [Backup compression](#backup_compression)

-   [Parallel backup and restore](#parallel_backup_restore)

-   [Retention Policy](#retention_policy)

-   [Configure repository location](#config_repo_location)

<div id='postgres_conn_details' class='registered_link'></div>

**Postgres connection details**


|   Tool        |   Configuration                                         |
|---------------|---------------------------------------------------------|
| BART          | In the [SERVER] section of  the config file: <br/>[example]<br/>...<br/>`host = localhost`<br/>`user = postgres` <br/>`port = 5432`|
| Barman        | In the config file: <br/> [example]<br/>...<br/>`conninfo = host=localhost user=postgres dbname=postgres`|
| pgBackRest[^*]| In the config file: <br/> [example]<br/>...<br/>`pg1-host = localhost`<br/>`pg1-path = /var/lib/postgres/data`<br/>`pg1-user = postgres`<br/>`port = 5432`|

 [^*] Specify pg1-path when pgBackRest is running locally, and specify pg1-host when pgBackRest is running remote
<div id='direct_file_copy_mode' class='registered_link'></div>

**Use of direct file copy mode (ssh or rsync) instead of pg_basebackup**

|   Tool     |   Configuration                                         |
|------------|---------------------------------------------------------|
| BART       | Increase threads >1 in the [SERVER] or [BART] section of the config file:<br/>[example]<br/>...<br/>`thread_count = 2`<br/>Or, as a commandline option<br/> `--no-pg_basebackup`|
| Barman     | In the config file: <br/>[example]<br/>...<br/>`backup_method = rsync`|
| pgBackRest | pgBackRest does not support pg_basebackup option|

<div id='incremental_backup' class='registered_link'></div>

**Incremental backups**

|   Tool     |   Configuration                                         |
|------------|---------------------------------------------------------|
| BART       | Retrieve the `backup_id` or `backup_name` for the parent:<br/>`bart SHOW-BACKUPS example`<br/>Now supply he `backup_id` or `backup_name` as parent:<br/>`bart BACKUP –s example --parent { backup_id \| backup_name }`|
| Barman     | In the config file:<br/>[example]<br/>...<br/>`reuse_backup = link`<br/>Or, as a command line option:<br/>`--reuse-backup=link`|
| pgBackRest | `pgbackrest --stanza=example --type=incr backup`|

<div id='wal_archive_compression' class='registered_link'></div>

**WAL archive compression**

|   Tool     |   Configuration                                         |
|------------|---------------------------------------------------------|
| BART       | In the [SERVER] or [BART] section of  the config file: <br/> [example]<br/>...<br/>`wal_compression = enabled`|
| Barman     | In the config file:<br/>[example]<br/>...<br/>`compression = gzip`|
| pgBackRest | Global compress settings. Can be overloaded for [global:archive-push]|

<div id='backup_compression' class='registered_link'></div>

**Backup compression**

|   Tool     |   Configuration                                         |
|------------|---------------------------------------------------------|
| BART       | Command line option: <br/>`Enable: --gzip`<br/>`Level: --compress-level`|
| Barman     | N/A|
| pgBackRest | `compress=y`<br/>`compress-level=9`<br/>`compress-type=gz`<br/>`compress-level-network=3`|


<div id='parallel_backup_restore' class='registered_link'></div>

**Parallel backup and restore**

|   Tool     |   Configuration                                         |
|------------|---------------------------------------------------------|
| BART       | Set `thread_cound` in the [SERVER] or [BART] section of  the config file:<br/> [example]<br/>...<br/>`thread_count = 4`<br/>Or, as a Command line option<br/> `--thread-count=4`|
| Barman     | Set `parallel_jobs` in the configfile:<br/>[example]<br/>...<br/>`parallel_jobs = 4`<br/>Or, as a command line option<br/> `--jobs 4`|
| pgBackRest | Set `process-max` in the configfile:<br/>[example]<br/>...<br/>`process-max = 4`<br/>Or, as a command line option<br/> `--process-max=4`|


<div id='retention_policy' class='registered_link'></div>

**Retention Policy**

|   Tool     |   Configuration                                         |
|------------|---------------------------------------------------------|
| BART       | Set `retention_policy` in the [SERVER] or [BART] section of the config file:<br/>[example]<br/>…<br/>`retention_policy = 2 BACKUPS` # Or DAYS, WEEKS, or MONTHS|
| Barman     | Set `retention_policy`, and/or `wal_retention_policy` options in the config file:<br/>[example]<br/>…<br/>`retention_policy =REDUNDANCY 2`<br/>or<br/>`retention_policy = RECOVERY WINDOW OF 2 DAYS` # WEEKS/MONTHS.|
| pgBackRest | Can be set in the config file:<br/>[example]…<br/>`repo-retention-full-type = count #can also be time`<br/>`repo-retention-full = 2`<br/>`repo-retention-diff = 6`<br/>`# Retain WAL archives for only 1 full backup:`<br/>`repo-retention-archive-type = full #can also be diff or incr`<br/>`repo-retention-archive = 1`<br/>See Retention Policy in [edb documentation](https://www.enterprisedb.com/docs/supported-open-source/pgbackrest/05-retention_policy/) for more information.|

<div id='config_repo_location' class='registered_link'></div>

**Configure repository location**

|   Tool     |   Configuration                                         |
|------------|---------------------------------------------------------|
| BART       | In the config file in the [BART] section:<br/>[BART]<br/>…<br/>`backup_path = /tmp/bart`|
| Barman     | In the config file in the main chapter:<br/>`backup_directory = /tmp/barman`|
| pgBackRest | [global]<br/>`repo1-path=/var/lib/pgbackrest`|



Scheduling
--------------

### Backup scheduling

Since BART, Barman, and pgBackRest all schedule the backups using cron,
changing the scheduling simply requires changing the scheduled commands.
Example commands for BART, Barman, and pgBackRest:

1.  Run a full backup for cluster \'example\':

|   Tool     |   Command                                               |
|------------|---------------------------------------------------------|
| BART       | `bart BACKUP –s example`|
| Barman     | `barman backup example`|
| pgBackRest | `pgbackrest backup --type=full --stanza=example`|


 
2.  Run a full backup for all configured servers:

|   Tool     |   Command                                               |
|------------|---------------------------------------------------------|
| BART       | `bart BACKUP –s all`|
| Barman     | `barman backup all`|
| pgBackRest | pgbackrest does not have an option to run for all stanzas with one command|

 

3.  Run an incremental backup:

|   Tool     |   Command                                               |
|------------|---------------------------------------------------------|
| BART       | Retrieve the `backup_id`/`backup_name` for the parent (select a full for an incremental, select another inc/diff for a differential backup plan):<br/>`bart SHOW-BACKUPS example`<br/>Now supply the `backup_id`/`backup_name` as parent:<br/>`bart BACKUP –s example --parent { backup_id \| backup_name }`<br/>|
| Barman     | `barman backup example --reuse-backup=link`<br/>This can also be set in the configuration file at the global/server level with `reuse_backup = link`|
| pgBackRest | Incremental:`pgbackrest backup --type=incr --stanza=example`<br/>Differential: `pgbackrest backup --type=diff --stanza=example`|


### Retention management

-   With BART usually a cron job is set up to run maintenance on the
    > BART repository (bart MANAGE). By supplying the -d option, the
    > obsoleted backups are automatically cleaned (together with their
    > WAL archives).

-   Similarly, Barman uses a cron command to run maintenance on the
    > Barman repository \`barman cron\`. The \`barman cron\` command
    > takes care of more things (like copying streamed WAL files to the
    > WAL archive directory), and needs to be scheduled to run every
    > minute. The Barman rpm or debian package automatically creates a
    > cron entry running every minute as the barman user.

-   pgBackRest runs maintenance with the expire command (pgbackrest
    > expire), but the expire command is run automatically after each
    > successful backup, and is not required to be separately scheduled.

While migrating to a new tool, make sure that cron is reconfigured to
run the proper retention management commands.

Restoring BART backups without using BART
===========================================

The repository formats for BART, Barman, and pgBackRest are different in
many ways, and there is no tool to convert BART repositories into
Barman/pgBackRest repositories. Furthermore,

-   BART full backups can only be restored with BART or manual
    > restoration procedures.

-   BART differential / incremental backups can only be restored through
    > BART

This chapter describes how to restore a full backup taken with BART, and
additionally how to use WAL archives to recover to a later point in
time, without requiring differential / incremental backups.

Location
------------

The files to be restored are kept in the BART repository. To locate the
files for a backup, the following information is important:

-   Backup\_path (BART section)

-   Servername (name of the Server section, e.a. Epas13 for \[epas13\])

-   Date/Time the backup was taken

The location for the exact backup is:

{backup\_path}/{servername\|lower}/{milliseconds since \"Unix epoch\"}.

As an example, for a bart.cfg file with the following entries:

+-----------------------------+
| \[BART\]                    |
|                             |
| backup\_path = /opt/backups |
|                             |
| \...                        |
|                             |
| \[EPAS13\]                  |
|                             |
| \...                        |
+-----------------------------+

The path for all backups would be

> /opt/backups/epas13/

A backup taken at first of January 2020, at 2 minutes and 3 seconds past
1AM, (01/01/2020 01:02:03:456 is ***1577840523456*** milliseconds since
Unix epoch), could be found in:

> /opt/backups/epas13/***1577840523456***/

Format
----------

The manual restoration procedures depend on the format that has been
chosen for the backup, which is dependant on the command line arguments
used when running the backup command:

  **Command Line option**         **Format**
  ------------------------------- -------------
  No option specified (default)   Tar
  -F=t                            Tar
  \--format=t                     Tar
  -F=t -z                         Gzipped Tar
  \--format=t -z                  Gzipped Tar
  -z                              Gzipped Tar
  -F=p                            Plain
  \--format=p                     Plain

### Tar format (default)

For Tar backups, the folder contains the following files:

  **File (/folder)**          **Description**
  --------------------------- ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  backup\_label, backupinfo   These files contain metadata regarding the backup, which is generated by pg\_basebackup and BART. They can be ignored during restore.
  base (folder)               For restoring Tar backups, this folder can be ignored.
  base.tar, base-{1-n}.tar    These are the tar files which contain the default data directory. These files need to be extracted to the restored PGDATA directory.
  {OID}-(1-n}.tar             These files start with a number (e.a. 16385-1.tar), and have follow up numbers (e.a. 16385-2.tar, 16385-3.tar, etc.). The initial (large) number is the OID for the tablespace that is contained in these tar files. These files need to be restored to the tablespace mount points, and referenced with a symbolic link in the pg\_tblspc folder.

To restore BART backups in the Tar format, perform the following steps:

1.  Copy the backup files to the database server locally, if needed

2.  Stop Postgres, if needed

3.  Clean the datadirectory and tablespace mount point if needed

> If you are recreating the datadir, make sure that ownership is set to
> enterprisedb (Advanced) or postgres (PostgreSQL). And make sure that
> permissions are set to 0700 (drwx\-\-\-\-\--).

4.  In the datadirectory, restore all the base\*.tar files. Example:

+------------------------------------------------------------------+
| cd \$PGDATA                                                      |
|                                                                  |
| for t in \$BACKUPFOLDER/base.tar \$BACKUPFOLDER/base-\*.tar ; do |
|                                                                  |
| tar -xvf \$t                                                     |
|                                                                  |
| done                                                             |
+------------------------------------------------------------------+

5.  The tablespace\_map (just restored from base.tar in \$PGDATA), holds
    > all entries for the tablespaces that used to exist. Every line has
    > the oid, and the original path. For each line, do the following:

    a.  Create the tablespace folder in the tablespace mountpoint if
        > needed

    b.  In the tablespace folder restore the contents of {oid}-\*.tar

    c.  Create a symlink in PGDATA/pg\_tblspcs/ to the tablespace folder

> Example script:

+-----------------------------------------------------------------+
| cat \$PGDATA/tablespace\_map \| while read line; do             |
|                                                                 |
| IFS=\' \' read -r -a array \<\<\< \"\$line\"                    |
|                                                                 |
| mkdir -p \"\${array\[1\]}\"                                     |
|                                                                 |
| cd \"\${array\[1\]}\"                                           |
|                                                                 |
| for t in \$BACKUPFOLDER/\"\${array\[0\]}\"-\*.tar ; do          |
|                                                                 |
| tar -xvf \$t                                                    |
|                                                                 |
| done                                                            |
|                                                                 |
| ln -s \"\${array\[1\]}\" \$PGDATA/pg\_tblspc/\"\${array\[0\]}\" |
|                                                                 |
| done                                                            |
+-----------------------------------------------------------------+

6.  Follow the steps in [[the recovery section]{.underline}](#recovery)

### Gzipped tar format

For GZipped backups, the folder structure is basically the same as for
tar formatted backups, but the tar files are gzipped, and have a .gz
suffix:

  **File (/folder)**               **Description**
  -------------------------------- ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  backup\_label, backupinfo        These files contain metadata regarding the backup, which is generated by pg\_basebackup and BART. They can be ignored during restore.
  base (folder)                    For restoring Tar backups, this folder can be ignored.
  base.tar.gz, base-{1-n}.tar.gz   These are the gzipped tar files which contain the default data directory. These files need to be extracted to the restored PGDATA directory.
  {OID}-(1-n}.tar.gz               These files start with a number (e.a. 16385-1.tar), and have followup numbers (e.a. 16385-2.tar, 16385-3.tar, etc.). The initial (large) number is the OID for the tablespace that is contained in these tar files. These files need to be restored to the tablespace mount points, and referenced with a symbolic link in the pg\_tblspc folder.

To restore BART backups in the Gzipped Tar format, perform the following
steps:

1.  Copy the backup files to the database server locally, if needed

2.  Stop Postgres, if needed

3.  Clean the datadirectory and tablespace mount point, if needed

> If you are recreating the datadir, make sure that ownership is set to
> enterprisedb (Advanced) or postgres (PostgreSQL). And make sure that
> permissions are set to 0700 (drwx\-\-\-\-\--).

4.  In the datadirectory, restore all the base\*.tar.gz files. Example:

+------------------------------------------------------------------------+
| cd \$PGDATA                                                            |
|                                                                        |
| for t in \$BACKUPFOLDER/base.tar.gz \$BACKUPFOLDER/base-\*.tar.gz ; do |
|                                                                        |
| tar -xvf \$t                                                           |
|                                                                        |
| done                                                                   |
+------------------------------------------------------------------------+

5.  The tablespace\_map (just restored from base.tar.gz in \$PGDATA),
    > holds all entries for the tablespaces that used to exist. Every
    > line has the oid, and the original path. For each line, do the
    > following:

    a.  Create the tablespace folder in the tablespace mountpoint, if
        > needed

    b.  In the tablespace folder restore the contents of {oid}-\*.tar.gz

    c.  Create a symlink in PGDATA/pg\_tblspcs/ to the tablespace folder

> Example script:

+-----------------------------------------------------------------+
| cat \$PGDATA/tablespace\_map \| while read line; do             |
|                                                                 |
| IFS=\' \' read -r -a array \<\<\< \"\$line\"                    |
|                                                                 |
| mkdir -p \"\${array\[1\]}\"                                     |
|                                                                 |
| cd \"\${array\[1\]}\"                                           |
|                                                                 |
| for t in \$BACKUPFOLDER/\"\${array\[0\]}\"-\*.tar.gz ; do       |
|                                                                 |
| tar -xvf \$t                                                    |
|                                                                 |
| done                                                            |
|                                                                 |
| ln -s \"\${array\[1\]}\" \$PGDATA/pg\_tblspc/\"\${array\[0\]}\" |
|                                                                 |
| done                                                            |
+-----------------------------------------------------------------+

6.  Follow the steps in [[the recovery chapter]{.underline}](#recovery)

Plain format
----------------

For Plain formatted backups, the folder contains the following files:

  **File**          **Description**
  ----------------- ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  backupinfo        This file contains metadata regarding the backup, which is generated by pg\_basebackup and BART. It can be ignored during restore.
  base (folder)     This contains the default data directory. These files need to be copied to the restored PGDATA directory.
  {OID} (/folder)   These folders names are large numbers (e.a. 16385), which in fact are the OID for the tablespace that is contained in these folders. These folders need to be restored to the tablespace mount points, and referenced with a symbolic link in the pg\_tblspc folder.

To restore BART backups in the Plain format, perform the following
steps:

1.  Copy the backup files to the database server locally, if needed

2.  Stop Postgres, if needed

3.  Clean the datadirectory and tablespace mount point, if needed

> If you are recreating the datadir, make sure that ownership is set to
> enterprisedb (Advanced) or postgres (PostgreSQL). And make sure that
> permissions are set to 0700 (drwx\-\-\-\-\--).

4.  Copy the contents of the base folder to the datadirectory. Example:

  -------------------------------------
  cp -r \$BACKUPDIR/base/\* \$PGDATA/
  -------------------------------------

5.  The tablespace\_map (just restored from base.tar.gz in \$PGDATA),
    > holds all entries for the tablespaces that used to exist. Every
    > line has the oid, and the original path. For each line, do the
    > following:

    a.  Create the tablespace folder in the tablespace mountpoint, if
        > needed

    b.  In the tablespace folder restore the contents of {oid}-\*.tar.gz

    c.  Create a symlink in PGDATA/pg\_tblspcs/ to the tablespace folder

> Example script:

+-----------------------------------------------------------------+
| cat \$PGDATA/tablespace\_map \| while read line; do             |
|                                                                 |
| IFS=\' \' read -r -a array \<\<\< \"\$line\"                    |
|                                                                 |
| mkdir -p \"\${array\[1\]}\"                                     |
|                                                                 |
| cp \$BACKUPDIR/\"\${array\[0\]}\" \"\${array\[1\]}\"            |
|                                                                 |
| ln -s \"\${array\[1\]}\" \$PGDATA/pg\_tblspc/\"\${array\[0\]}\" |
|                                                                 |
| done                                                            |
+-----------------------------------------------------------------+

6.  Follow the steps in [[the recovery chapter]{.underline}](#recovery)

Recovery
------------

The steps for recovery depend on the Postgres version:

-   With Postgres and Advanced versions 9.6 - 11, a recovery.conf file
    > should be created.

-   With Postgres and Advanced versions 12, and 13, the recovery
    > parameters are configured in postgresql.conf. Make sure that the
    > PGDATA/recovery.signal file is created so that PostgreSQL will
    > initiate the recovery process.

Make sure that the restore\_command is configured, and can be used to
restore the wal files. Without setting a recovery\_target\* option
Postgres will recover to the latest point in time available in the wal
files. For more information and other options, please refer to [[the
PostgreSQL 11
documentation]{.underline}](https://www.postgresql.org/docs/11/recovery-config.html),
or [[the PostgreSQL 13
documentation]{.underline}](https://www.postgresql.org/docs/current/continuous-archiving.html).

[^1]:
